[General]
# list of files of the initial subread fasta files
input_fofn = input.fofn

# If you set the option input_type = preads rather 
# than input_type = raw, fc_run.py will assume the 
# fasta files in input_fofn are all error-corrected 
# reads and it will ignore any error correction step 
# and go directly into the final assembly overlapping step.
input_type = raw
#input_type = preads

# You will need to decide the length cutoff. Typically, 
# it will be nice to chose the threshold at the point 
# you can get longest 15x to 20x for genome assembly. 
# However, if the computational resource is abundant 
# and you might find other applications of error corrected 
# reads, you can set lower length cutoff to get more 
# error corrected reads for your applications.
# The option length_cutoff controls the cutoff used 
# during the error correction process and length_cutoff_pr 
# controls the cutoff used for the later assembly overlapping 
# step. In the final assembly, more reads may not lead 
# to a better assembly due to some of the reads can be 
# noisy and create false links in the assembly graph. 
# Sometimes, it might make sense to try different 
# length_cutoff_pr as it is relative cheap for computation 
# than the first overlapping step for error correction. 
# One strategy is to choose a smaller length_cutoff and 
# do the computation once. Later, we can use different 
# length_cutoff_pr for getting better assembly.

# The length cutoff used for seed reads used for initial mapping
length_cutoff = 3000

# The length cutoff used for seed reads used for pre-assembly
length_cutoff_pr = 3000


# The option pa_concurrent_jobs controls the number of 
# concurrent jobs that can be submitted by fc_run.py. 
# sge_option_da and sge_option_la control the job queue 
# and the number of slots of the daligner jobs. 
# The default number of thread used by daligner is 4.

# Cluster queue setting
# In order to run on a cluster, the job_type parameter 
# would need to be changed from "local" to "SGE", the 
# sge_option_* flags would need to be supplied with the 
# flags necessary to run on this particular SGE setup, 
# and the number of concurrent jobs would need to be increased.
job_type=local
sge_option_da = -pe mpich 10 -q Annotation-4
sge_option_la = -pe mpich 2 -q Annotation-4
sge_option_pda = -pe mpich 10 -q Annotation-4
sge_option_pla = -pe mpich 2 -q Annotation-4
sge_option_fc = -pe mpich 20 -q Annotation-4
sge_option_cns = -pe mpich 10 -q Annotation-4

# concurrency setting
# One can use cns_concurrent_jobs to control the maximum number 
# of concurrent jobs submitted to the job management system.
pa_concurrent_jobs = 4
cns_concurrent_jobs = 4
ovlp_concurrent_jobs = 4


# Overlapping options for Daligner
# Daligner is controlled by pa_HPCdaligner_option and ovlp_HPCdaligner_option.
# To limit memory, one can use the “-M” option. For human assembly, 
# we tested with -M 32 for using 32G RAM for each daligner. 
# Other possibilities are under investigation.
# For more details on daligner options, see dazzlerblog.
#
# The total number of jobs that are run is determined by how one 
# "splits" the sequence database. You should read Gene Myers's 
# blog ( http://dazzlerblog.wordpress.com ) carefully to know how 
# to tune the option pa_DBsplit_option and pa_HPCdaligner_option. 
# Generally, for large genomes, you should use -s400 (400Mb 
# sequence per block) in pa_DBsplit_option. This will make a smaller 
# number of jobs but each job will run longer. However, if you have 
# a job queue system which limits how long a job can run, it might 
# be desirable to have a smaller number for the -s option.
#
# Another parameter that affects the total number of jobs is the -B 
# (earlier called -dal) option in pa_HPCdaligner_option. The number 
# for the -dal option determines how many blocks are compared to each 
# in single jobs. Larger number gives larger jobs but smaller amount 
# of total jobs. Smaller number gives smaller jobs but you have to 
# submit more jobs to your cluster.
#
#In this workflow, the trace point generated by daligner is not used. 
# ( Well, to be efficient, one should use the trace points but one 
# have to know how to pull them out correctly first. ) The -s1000 in 
# pa_HPCdaligner_option makes the trace points sparse to save some 
# disk space (not much though). We also ignore all reads less than 
# 1kb by specifying -l1000.
pa_HPCdaligner_option =  -v -B128 -t6 -e0.70 -l1000 -s100 -H7000 -M24 -h240 -w8 -k21
ovlp_HPCdaligner_option = -v -B128 -h240 -e.96 -l1000 -s100 -H7000 -k24

pa_DBsplit_option = -x500 -s50
ovlp_DBsplit_option = -x500 -s50

# Error correction consensus options
# In most cases, the --min_cov and --max_n_read are the most important 
# options. --min_cov controls when a seed read gets trimmed or broken 
# due to low coverage. --max_n_read puts a cap on the number of reads 
# used for error correction. In highly repetitive genome, you will 
# need to put smaller --max_n_read to make sure the consensus code 
# does not waste time aligning repeats. The longest proper overlaps 
# are used for correction to reduce the probability of collapsed repeats.
falcon_sense_option = --output_multi --min_idt 0.70 --min_cov 3 --max_n_read 200 --n_core 6

# Overlap filtering options
#
# The setting is mostly parallel to the first overlapping step. 
# The major difference is the -e option in ovlp_HPCdaligner_option. 
# The error rate is much lower now so we expect much higher correlation between the p-reads.
#
# Not all overlaps are "independent", so it is possible to impose 
# some filtering step to reduce computation and assembly graph 
# complexity. For example, if a read is fully contained in another 
# read, the overlap information between these two reads does not 
# provide extra information for re-constructing the genome. Also, 
# due to the transitive property of the overlapping relations, a 
# lot of overlap information can be simply inferred. In fact, the 
# first stage for constructing contigs are to remove the transitive 
# reducible edges. It means that we might just needs the "best n 
# overlaps" in the 5' or 3' ends. The --bestn parameter in 
# overlap_filtering_setting option can be used to control the 
# maximum overlap reported for each read.
#
# Another useful heuristics is to only keep reads that have average 
# 5' and 3' coverage. That's because if a read ends in a repeat, it 
# might have higher than normal coverage at the end which is a repeat. 
# And such reads do not provide much value for uniquely resolving the 
# related repeats. We can filter them out and hopefully there are 
# reads which span through the repeats and have "normal" unique 
# anchors on both ends. Also, if the coverage is too low on one end 
# of a read, it could be just too many errors or sequencing artifacts 
# over there. Such reads create "spurs" in the assembly graph which 
# are typically filtered out anyway. The --max_cov and --min_cov are 
# used for filtering reads that have too high or too low overlaps.
#
# The filtering scripts also allows filtering out some "split" reads. 
# If a read have very unequal coverage between the 5' and 3' ends, it 
# can be also a signal that one end is a repeat. The --max_diff 
# parameter can be used to filter out the reads where one ends has 
# much more coverage than the other end.
#
# What is the right numbers used for these parameters? These parameters 
# may the most tricky ones to be set right. If the overall coverage of 
# the error corrected reads longer than the length cut off is known 
# and reasonable high (e.g. greater than 20x), it might be safe to 
# set min_cov to be 5, max_cov to be three times of the average 
# coverage and the max_diff to be twice of the average coverage. 
# However, in low coverage case, it might better to set min_cov 
# to be one or two. A helper script called fc_ovlp_stats.py can 
# help to dump the number of the 3' and 5' overlap of a given 
# length cutoff, you can plot the distribution of the number of 
# overlaps to make a better decision.
# One can also set the max_diff and max_cov to be really high to 
# avoid any filtering if that is preferred in some cases.
#
# This filtering process will certainly filter out information 
# about high copy repeats. Namely, those repeats will likely 
# to be filtered out totally and do not appear in the final 
# assembly. If you are interested in those repeats even though 
# they may not be able to placed within some longer contig, you 
# will probably want to avoid filtering them out or process them 
# differently. In general, it might be more efficient and useful 
# to process those repeats separately. Including them in the 
# assembly process typically does not help much for getting 
# better contiguity and maybe messy for post-processing with 
# current algorithms. I think it is a very interesting but 
# also very challenging bioinformatics topic on how to process 
# these repeats better for improving assembly beside understand 
# the nature of these repeats.
overlap_filtering_setting = --max_diff 500 --max_cov 1000 --min_cov 3 --bestn 10 --n_core 6
